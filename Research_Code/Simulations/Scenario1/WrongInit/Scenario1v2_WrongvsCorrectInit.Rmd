---
title: "MSM_Hom_exploration"
author: "Gomon, Daniel"
date: "17/05/2024"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Goal of this file

In this file, we investigate the estimates from our simulation study in the time-homogeneous case.
We want to compare the estimates to the oracle on:
- MSE at unique time points
- supremum norm over the unique time points
- Graphically display the cumulative intensities


# Scenario information - Adjust here to get appropriate output.

```{r}
scenario <- 1 #Choose from 1:4
n <- c(100, 300, 500) #Remove one if no files
n_obs <- c(6) #At most c(3,6)
N <- 1000
methods <- c("poisson", "poisson")

eval_times <- seq(0, 15, 0.1)
w_shapes <- c(0.5, 0.5, 2)
w_scales <- c(5, 10, 10/gamma(1.5))
```



```{r echo = FALSE}
#Create file names to load:
load_names <- expand.grid(scenario, n, n_obs, N, methods)
#Because we have only ran n <- 500 with N <- 500 we need an extra line:
which500 <- which(load_names[, 2] == 500)
#load_names[which500, 4] <- 500
load_names[4:6, 4] <- 200
colnames(load_names) <- c("scenario", "n", "n_obs", "N", "method")
load_names[, 5] <- as.character(load_names[, 5])
names_load <- c()
var_names <- c()
for(i in 1:nrow(load_names)){
  x <- load_names[i,]
  names_load <- c(names_load, paste0("sc", x[1], "n", x[2], "obs", trimws(x[3]), "N", x[4], x[5], ".Rdata"))
  var_names <- c(var_names, paste0("sc", x[1], "n", x[2], "obs", trimws(x[3]), "N", x[4], x[5]))
}
```


# Loading the data


```{r echo = FALSE}
for(i in 1:length(names_load)){
  load(names_load[i])
}

#Check which runs failed
for(i in 1:length(var_names)){
  which_failed <- sapply(get(var_names[i]), function(x) is.character(x))
  assign(var_names[i], get(var_names[i])[!which_failed])
}

#Take only 200 first runs of normal initial conditions
for(i in 1:3){
  assign(var_names[i], get(var_names[i])[1:200])
}

```



# Loading the necessary packages

```{r echo = FALSE}
library(icmstate)
library(ggplot2)
library(ggpubr)
```


# Functions

## Function to plot cumulative intensities.


```{r echo = FALSE}
create_plot_df <- function(dat){
  if(inherits(dat[[1]], "npmsm")){
    plot_df <- NULL
    for(i in 1:length(dat)){
      plot_df <- rbind(plot_df, cbind(dat[[i]]$A$Haz, i))
    }
    colnames(plot_df) <- c("time", "Haz", "trans", "id")
    return(plot_df)  
  } else if(inherits(dat[[1]], "msm")){
    plot_df <- NULL
    for(i in 1:length(dat)){
      plot_df <- rbind(plot_df, cbind(exp(dat[[i]]$estimates), c(1,2,3), rep(i, 3)))
    }
    colnames(plot_df) <- c("slope", "trans", "id")
    return(as.data.frame(plot_df))
  }
}

```


## Function for MSE over whole time-frame

```{r echo = FALSE}
oracle_haz <- function(t, trans){
  if(trans == 2){
    return(0.05*t)
  } else{
    return(0.1*t)
  }
}

get_MSE_dat <- function(dat){
  MSE_samp <- array(NA, dim = c(length(dat), 3))
  for(i in 1:length(dat)){
    times <- unique(dat[[i]]$A$Haz$time)
    n_times <- length(times)
    oracle_haz <- sapply(1:3, function(x) oracle_haz(t = times, trans = x))
    dat_haz <- array(dat[[i]]$A$Haz$Haz, dim = c(n_times, 3))
    MSE_samp[i,] <- colMeans((dat_haz - oracle_haz)^2)
  }
  colnames(MSE_samp) <- paste0("trans", c(1,2,3))
  MSE_samp
}
#get MSE dat returns a data frame with each column representing a transition and each row representing a sample from the simulation study.
```



## Function to determine interpolation of cumulative hazard, taking into account the support sets.

```{r echo = FALSE}
interpol_support <- function(msfit, trans){
  #We want to return the value of Cumulative hazard right at the time smaller or equal to current time
  transno <- trans
  Haz <- rbind(c(0, 0, trans), subset(msfit$Haz, trans == transno))
  cumhaz_fct <- function(t){
    indices <- findInterval(t, Haz$time, left.open = TRUE, rightmost.closed = TRUE)
    Haz$Haz[indices]
  }
  return(cumhaz_fct)
}

interpol_support_msm <- function(msm, trans){
  haz_rates <- exp(msm$estimates)
  return(function(t) ifelse(is.na(haz_rates[trans]), 0, haz_rates[trans] * t))
}
```

Interpol support returns the linear interpolation of estimated cumulative intensities.


## Function to plot the interpolated cumulative hazards

```{r echo = FALSE}
create_plot_df_interpol <- function(dat, eval_times){
  plot_df <- NULL
  transitions <- dat[[1]]$tmat2$transno
  for(i in 1:length(dat)){
    for(j in transitions){
      fun <- interpol_support(dat[[i]]$A, j)
      Haz <- fun(eval_times)
      plot_df <- rbind(plot_df, cbind(eval_times, Haz, j, i))
    }
  }
  colnames(plot_df) <- c("time", "Haz", "trans", "id")
  return(as.data.frame(plot_df))
}
#Given data and evaluation times, determine the interpolated cumulative intensities and output a data frame that can be used for plotting.
```





## Functions for time-specific extraction of statistics (RMSE, Bias, Variance)



```{r echo = FALSE}
#First we create a data-set where we have all the information we use to calculate summary statistics.
create_summary_df <- function(dat, eval_times){
  #Number of transitions
  if(inherits(dat[[1]], "npmsm")){
    M <- nrow(dat[[1]]$tmat2)  
  } else{
    M <- length(dat[[1]]$estimates)
  }
  
  #Number of evluation times
  n_times <- length(eval_times)
  #Number of replicates
  n_reps <- length(dat)
  df <- matrix(NA, nrow = n_reps * n_times, ncol = M + 2)
  for(i in 1:length(dat)){
    if(inherits(dat[[i]]$A, "msfit")){
      df[((i-1)*n_times +1):(i*n_times), 1:M] <- sapply(1:M, function(x) interpol_support(dat[[i]]$A, x)(eval_times))  
    } else{
      df[((i-1)*n_times +1):(i*n_times), 1:M] <- sapply(1:M, function(x) sapply(eval_times, function(t) interpol_support_msm(dat[[i]], x)(t)))   
    }
    df[((i-1)*n_times +1):(i*n_times), M+1] <- eval_times
    df[((i-1)*n_times +1):(i*n_times), M+2] <- rep(i, n_times)
  }
  colnames(df) <- c(paste0("trans", 1:M), "time", "id")
  return(df)
}
```



Now we can calculate summary statistics (RMSE, Bias, Variance):

```{r echo = FALSE}
extract_summary_stat <- function(summary_df, oracle_df, eval_times){
  M <- ncol(summary_df) - 2
  out_df <- NULL
  for(i in 1:length(eval_times)){
    current_time <- eval_times[i]
    relevant_df <- summary_df[summary_df[, "time"] == current_time, 1:M, drop = FALSE]
    relevant_oracle <- oracle_df[oracle_df[, "time"] == current_time, 1:M, drop = FALSE]
    #dat_trans contains difference between oracle hazard and estimated hazard for each transition (columns) for each repeat (rows)
    dat_trans <- t(apply(relevant_df, 1, function(x) x - relevant_oracle))
    #we therefore apply summary statistics to the columns to obtain them per transition
    stats <- c(t(apply(dat_trans, 2, function(x) c(mean(x), var(x), sqrt(var(x) + mean(x)^2)))))
    out_df <- rbind(out_df, data.frame(stats = stats, 
                                       type = rep(c("Bias", "Var", "RMSE"), each = 3),
                                       time = rep(current_time, M*3),
                                       trans = rep(1:M, 3)))
  }
  return(out_df)
}

```



```{r echo = FALSE}
#But we also want to calculate summary statistics for plotting (Mean, Median, SE, Quantiles (2.5/97.5))
extract_summary_stat_plotting <- function(summary_df, eval_times){
  M <- ncol(summary_df) - 2
  out_df <- NULL
  for(i in 1:length(eval_times)){
    current_time <- eval_times[i]
    relevant_df <- summary_df[summary_df[, "time"] == current_time, 1:M, drop = FALSE]
    
    #Extract statistics from relevant data
    stats <- c(t(apply(relevant_df, 2, function(x) c(mean(x), median(x), mean(x) + qnorm(0.975)* sd(x), mean(x) - qnorm(0.975)* sd(x), quantile(x, probs = c(0.025, 0.975))))))
    #Bind them into output data frame
    out_df <- rbind(out_df, data.frame(stats = stats, 
                                       type = rep(c("Mean", "Median", "uCI", "lCI", "q2.5", "q97.5"), each = M),
                                       time = rep(current_time, M*6),
                                       trans = rep(1:M, 6)))
  }
  return(out_df)
}
```


# Plotting + Stats

## Plot the cumulative intensities of simulated samples

Plot the cumulative intensities of the first $20$ 

```{r fig.keep='all'}
#oracle if we are in scenarios 1/2/4
if(scenario != 3){
  oracle_plot_df <- data.frame(trans = c(1, 2, 3), slope = c(0.1, 0.05, 0.1))  
} else{
  oracle_plot_df <- data.frame(time = rep(eval_times, 3), 
                               Haz = c(-pweibull(eval_times, shape = w_shapes[1], scale = w_scales[1], lower = FALSE, log = TRUE),
                                       -pweibull(eval_times, shape = w_shapes[2], scale = w_scales[2], lower = FALSE, log = TRUE),
                                       -pweibull(eval_times, shape = w_shapes[3], scale = w_scales[3], lower = FALSE, log = TRUE)),
                               trans = rep(c(1,2,3), each = length(eval_times)),
                               id = -1)
}

```

```{r eval = FALSE}

for(i in 1:length(var_names)){
  plot_df <- create_plot_df(get(var_names[i])[1:20])
  if(load_names[i, "method"] == "msm"){
    plot_20 <- ggplot(plot_df) + geom_abline( aes(intercept = 0, slope = slope, group = id, col = as.factor(id))) + facet_grid(trans~., scales = "free") + ggtitle(paste0("First 20 cumulative intensities of ", var_names[i]))
  } else{
    plot_20 <- ggplot(plot_df, aes(x = time, y = Haz, group = id, col = as.factor(id))) + geom_line() + facet_grid(trans~., scales = "free") + ggtitle(paste0("First 20 cumulative intensities of ", var_names[i]))
  }
  
  #Different oracle for Weibull
  if(scenario != 3){
    plot_20 <- plot_20 + geom_abline(data = oracle_plot_df, aes(intercept = 0, slope = slope), lwd = 2, col = "black")
  } else{
    plot_20 <- plot_20 + geom_line(data = oracle_plot_df, aes(x = time, y = Haz), lwd = 2, col = "black")
  }
  print(plot_20)
}

```




## MSE over whole time frame (per sample)


Currently not implemented! Not very interesting I think and a pain to evaluate.



# Determine time-specific statistics of data using interpolation 


Also no longer implemented, because not very interesting, interpolation doesn't change the visuals much.




## Use the written functions to get a visual display


We create an oracle:
```{r}
if(scenario != 3){ #Homogeneous oracle
  oracle_df <- matrix(NA, nrow = length(eval_times), ncol = 5)
  oracle_df[, 1] <- 0.1*eval_times
  oracle_df[, 2] <- 0.05*eval_times
  oracle_df[, 3] <- 0.1*eval_times
  oracle_df[, 4] <- eval_times
  oracle_df[, 5] <- rep(0, length(eval_times))
  colnames(oracle_df) <- c(paste0("trans", 1:3), "time", "id")  
} else{ #Weibull oracle
  oracle_df <- matrix(NA, nrow = length(eval_times), ncol = 5)
  oracle_df[, 1] <- -pweibull(eval_times, shape = w_shapes[1], scale = w_scales[1], lower = FALSE, log = TRUE)
  oracle_df[, 2] <- -pweibull(eval_times, shape = w_shapes[2], scale = w_scales[2], lower = FALSE, log = TRUE)
  oracle_df[, 3] <- -pweibull(eval_times, shape = w_shapes[3], scale = w_scales[3], lower = FALSE, log = TRUE)
  oracle_df[, 4] <- eval_times
  oracle_df[, 5] <- rep(0, length(eval_times))
  colnames(oracle_df) <- c(paste0("trans", 1:3), "time", "id")  
}


```


## Plot time-dependent summary statistics

```{r}
for(i in 1:nrow(load_names)){
  assign(paste0("summary_df", i), suppressWarnings(create_summary_df(get(var_names[i]), eval_times = eval_times)))
}
for(i in 1:nrow(load_names)){
  assign(paste0("stat_df", i), extract_summary_stat(summary_df = get(paste0("summary_df", i)), oracle_df = oracle_df, eval_times = eval_times))
}
```



Compare the statistics as n increases.

```{r fig.keep='all', eval = FALSE}
for(i in 1:length(methods)){
  stat_multiple <- NULL
  for(j in 1:length(n)){
    stat_multiple <- rbind(stat_multiple, get(paste0("stat_df", (i-1)*length(n)+j)))
  }
  stat_multiple <- cbind(stat_multiple, c(rep(n, each = length(eval_times) * 9)))
  colnames(stat_multiple)[5] <- "n"
  plot_all_stat <- ggplot(data = stat_multiple, aes(x = time, y = stats, group = interaction(type, n), col = as.factor(n), linetype = as.factor(type))) + geom_line() + facet_grid(trans~., scales = "free") + ggtitle(paste0("Comparison of statistics for method ", load_names[length(n)*i, 5] ))
  print(plot_all_stat)
}
```





## Compare between methods 



```{r}
trans_names <- c("1.Alive -> 2.Illness", "1.Alive -> 3.Death", "2.Illness -> 3.Death")
names(trans_names) <- c(1, 2, 3)
method_names <- c("Unfortunate", "Uniform")
names(method_names) <- c("unfortunate", "uniform")

init_cond <- c("uniform", "unfortunate")
for(i in 1:length(n)){
  stat_multiple <- NULL
  for(j in 1:length(methods)){
    stat_multiple <- rbind(stat_multiple, get(paste0("stat_df", i + length(n)*(j-1))))
  }
  stat_multiple <- cbind(stat_multiple, c(rep(init_cond, each = length(eval_times) * 9)))
  colnames(stat_multiple)[5] <- "Method"
  plot_all_stat <- ggplot(data = stat_multiple, aes(x = time, y = stats, group = interaction(type, as.factor(Method)), col = as.factor(Method), linetype = as.factor(type))) + geom_line(lwd = 1.2) + facet_grid(trans~., scales = "free", labeller = as_labeller(trans_names)) + xlab("Time (Years)") + ylab("Value") + labs(title = "Poisson EM", subtitle = paste0("Scenario ", scenario, "(N = 200)",  ", n = ", n[i]), color = "Initial Conditions", linetype = "Measure") + scale_color_brewer(palette="Dark2", labels = method_names) 
  print(plot_all_stat)
  assign(paste0("plot_all_stat", i), plot_all_stat)
}

all_stat_plot <- ggarrange(plot_all_stat1, plot_all_stat2, plot_all_stat3, 
          labels = c("A", "B", "C"),
          ncol = 3, nrow = 1, common.legend = TRUE, legend = "bottom")


ggsave(file = paste0("Scenario", scenario, "wronginitgg_intensities.eps"), plot = all_stat_plot, width = 5.5, height = 3, units = "in", scale = 1.7)

```


We clearly see that with unfortunate initial conditions we can get very high biases for Poisson. So it's not really doing better.








